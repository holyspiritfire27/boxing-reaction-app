import cv2
import av
import numpy as np
import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, RTCConfiguration, WebRtcMode
import mediapipe as mp
import time
import random
import math
from PIL import ImageFont, ImageDraw, Image
from collections import deque

# ================= é…ç½®èˆ‡å¸¸æ•¸ =================
st.set_page_config(page_title="æ‹³æ“Šåæ‡‰ v26 (é€²éšç‰ˆ)", layout="wide", page_icon="ğŸ¥Š")

# é¡è‰²å®šç¾© (B, G, R)
COLOR_CYAN = (255, 255, 0)    # å·¦æ‹³æç¤ºè‰² (OpenCVæ˜¯BGR)
COLOR_RED = (50, 50, 255)     # å³æ‹³æç¤ºè‰²
COLOR_TEXT = (255, 255, 255)
COLOR_STROKE = (0, 0, 0)

# ç‰©ç†å¸¸æ•¸
SHOULDER_WIDTH_M = 0.45  # å‡è¨­ä¸€èˆ¬äººè‚©å¯¬ 0.45 å…¬å°º (ç”¨æ–¼åƒç´ è½‰ç±³)

class BoxingAnalystLogic:
    def __init__(self):
        # MediaPipe åˆå§‹åŒ–
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(
            min_detection_confidence=0.7,
            min_tracking_confidence=0.7,
            model_complexity=1
        )
        
        # ç‹€æ…‹æ©Ÿ: WAIT_GUARD -> COUNTDOWN -> STIMULUS -> RESULT -> WAIT_NEXT
        self.state = 'WAIT_GUARD'
        self.start_time = 0
        self.stimulus_time = 0
        self.target = None # 'LEFT' or 'RIGHT'
        self.feedback_end_time = 0
        
        # ç‰©ç†è¨ˆç®—è®Šæ•¸
        self.prev_landmarks = None
        self.prev_time = 0
        self.max_speed = 0.0
        self.punch_detected_time = 0
        self.punch_start_pos = None
        self.punch_end_pos = None
        
        # è¨ˆæ•¸å™¨
        self.total_tests = 10
        self.current_test = 0
        self.guard_start_time = 0
        self.guard_required_time = 3.0  # ç¬¬ä¸€æ¬¡éœ€è¦3ç§’ï¼Œä¹‹å¾Œ2ç§’
        
        # æ­·å²æ•¸æ“š - åˆ†å·¦å³æ‰‹è¨˜éŒ„
        self.left_history = {"reaction": [], "speed": []}
        self.right_history = {"reaction": [], "speed": []}
        self.last_result = {"reaction": 0, "speed": 0, "rating": "", "speed_rating": "", "hand": ""}
        
        # æ¸¬è©¦çµæœæ‘˜è¦
        self.test_completed = False
        self.summary_data = {
            "left_avg_reaction": 0,
            "right_avg_reaction": 0,
            "left_avg_speed": 0,
            "right_avg_speed": 0,
            "left_rating": "",
            "right_rating": "",
            "overall_rating": ""
        }

        # å­—å‹åŠ è¼‰
        self.font_path = "font.ttf"
        self.use_chinese = False
        try:
            ImageFont.truetype(self.font_path, 20)
            self.use_chinese = True
        except:
            print("æœªæ‰¾åˆ°å­—å‹æª”ï¼Œå°‡ä½¿ç”¨é è¨­å­—é«”")
            
        # é€Ÿåº¦è¨ˆç®—ç·©è¡å€
        self.speed_buffer = deque(maxlen=5)
        self.velocity_history = []

    def put_chinese_text(self, img, text, pos, color, size=30, stroke_width=0):
        """ ä½¿ç”¨ PIL ç¹ªè£½é«˜å“è³ªä¸­æ–‡ (å«æé‚Š) """
        if not self.use_chinese:
            cv2.putText(img, text, pos, cv2.FONT_HERSHEY_SIMPLEX, size/30, color, 2)
            return img
            
        img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(img_pil)
        try:
            font = ImageFont.truetype(self.font_path, size)
            # è½‰æ›é¡è‰² BGR -> RGB (PIL ä½¿ç”¨ RGB)
            pil_color = (color[2], color[1], color[0])
            draw.text(pos, text, font=font, fill=pil_color, stroke_width=stroke_width, stroke_fill=(0,0,0))
        except Exception as e:
            print(f"Font Error: {e}")
            
        return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

    def get_landmarks(self, results, width, height):
        """ è§£æé—œéµé»åº§æ¨™ """
        if not results.pose_landmarks:
            return None
            
        lm = results.pose_landmarks.landmark
        
        # æå–é—œéµé» (11,12è‚©è†€; 13,14æ‰‹è‚˜; 15,16æ‰‹è…•)
        coords = {}
        key_points = {
            'L_SH': 11, 'R_SH': 12,
            'L_EL': 13, 'R_EL': 14,
            'L_WR': 15, 'R_WR': 16,
            'NOSE': 0
        }
        
        for name, idx in key_points.items():
            # x, y æ˜¯åƒç´ åº§æ¨™, z æ˜¯ç›¸å°æ·±åº¦
            coords[name] = np.array([lm[idx].x * width, lm[idx].y * height, lm[idx].z * width])
            
        return coords

    def calculate_speed_advanced(self, current_coords, dt):
        """ æ”¹é€²çš„æ‹³é€Ÿè¨ˆç®—æ–¹æ³• """
        if not self.prev_landmarks or dt <= 0:
            return 0.0
            
        # 1. è¨ˆç®—åƒç´ æ¯”ä¾‹å°º
        shoulder_dist_px = np.linalg.norm(current_coords['L_SH'][:2] - current_coords['R_SH'][:2])
        if shoulder_dist_px < 10: 
            return 0.0
        
        pixels_per_meter = shoulder_dist_px / SHOULDER_WIDTH_M
        
        # 2. åˆ¤æ–·å‡ºæ‹³æ‰‹ä¸¦è¨˜éŒ„è»Œè·¡
        active_wrist = 'L_WR' if self.target == 'LEFT' else 'R_WR'
        
        # 3. è¨ˆç®—3Dä½ç§»
        curr_pos = current_coords[active_wrist]
        prev_pos = self.prev_landmarks[active_wrist]
        
        # 3Dè·é›¢è¨ˆç®— (è€ƒæ…®æ·±åº¦)
        dx = curr_pos[0] - prev_pos[0]
        dy = curr_pos[1] - prev_pos[1]
        dz = curr_pos[2] - prev_pos[2]
        dist_px = math.sqrt(dx*dx + dy*dy + dz*dz*0.3)  # zè»¸æ¬Šé‡é™ä½
        
        # 4. è¨ˆç®—å³æ™‚é€Ÿåº¦
        speed_mps = (dist_px / pixels_per_meter) / dt
        
        # 5. éæ¿¾å’Œå¹³æ»‘
        self.speed_buffer.append(speed_mps)
        smoothed_speed = np.mean(self.speed_buffer)
        
        # 6. ä¿å­˜é€Ÿåº¦æ­·å²ç”¨æ–¼å³°å€¼æª¢æ¸¬
        self.velocity_history.append(smoothed_speed)
        if len(self.velocity_history) > 20:
            self.velocity_history.pop(0)
        
        # 7. ç‰©ç†åˆç†æ€§æª¢æŸ¥
        if smoothed_speed > 25:  # äººé¡æ¥µé™ç´„20-22 m/s
            return 0.0
            
        return smoothed_speed

    def detect_punch_movement(self, coords):
        """ æª¢æ¸¬å‡ºæ‹³å‹•ä½œ """
        if not coords:
            return False
            
        active_wrist = 'L_WR' if self.target == 'LEFT' else 'R_WR'
        active_elbow = 'L_EL' if self.target == 'LEFT' else 'R_EL'
        
        # 1. æ‰‹è‚˜è§’åº¦æª¢æ¸¬
        shoulder = coords['L_SH'] if self.target == 'LEFT' else coords['R_SH']
        elbow = coords[active_elbow]
        wrist = coords[active_wrist]
        
        # è¨ˆç®—æ‰‹è‡‚è§’åº¦
        v1 = elbow[:2] - shoulder[:2]
        v2 = wrist[:2] - elbow[:2]
        
        if np.linalg.norm(v1) == 0 or np.linalg.norm(v2) == 0:
            return False
            
        cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
        cos_angle = np.clip(cos_angle, -1, 1)
        angle = math.degrees(math.acos(cos_angle))
        
        # å‡ºæ‹³æ™‚æ‰‹è‡‚è¶¨å‘ä¼¸ç›´ (è§’åº¦æ¥è¿‘180åº¦)
        if angle > 150:  # æ‰‹è‡‚è¼ƒç›´
            # 2. æ–¹å‘ä¸€è‡´æ€§æª¢æ¸¬ (æ‰‹è‡‚å‘å‰ç§»å‹•)
            if self.prev_landmarks:
                wrist_movement = wrist[:2] - self.prev_landmarks[active_wrist][:2]
                # æª¢æŸ¥æ˜¯å¦å‘å‰ç§»å‹• (å‡è¨­é¡é ­æ–¹å‘)
                if wrist_movement[0] > 0:  # å‘å³ç§»å‹• (å› ç‚ºç•«é¢é¡åƒ)
                    return True
                    
        return False

    def process(self, img):
        # 1. å½±åƒå‰è™•ç†
        img = cv2.flip(img, 1)  # é¡åƒ
        h, w, _ = img.shape
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = self.pose.process(img_rgb)
        
        current_time = time.time()
        dt = current_time - self.prev_time
        self.prev_time = current_time
        
        coords = self.get_landmarks(results, w, h)
        
        # ç¹ªè£½éª¨æ¶ (è¦–è¦ºå›é¥‹)
        if results.pose_landmarks:
            mp.solutions.drawing_utils.draw_landmarks(
                img, results.pose_landmarks, self.mp_pose.POSE_CONNECTIONS)

        # é¡¯ç¤ºæ¸¬è©¦é€²åº¦
        if not self.test_completed:
            progress_text = f"æ¸¬è©¦é€²åº¦: {self.current_test}/{self.total_tests}"
            img = self.put_chinese_text(img, progress_text, (w-250, 30), (255, 255, 255), 30)

        # ç‹€æ…‹æ©Ÿé‚è¼¯
        if self.state == 'WAIT_GUARD':
            # é¡¯ç¤ºæŒ‡å¼•
            if self.current_test == 0:
                req_time = 3.0
            else:
                req_time = 2.0
                
            img = self.put_chinese_text(img, f"è«‹æ“ºå‡ºæ ¼é¬¥å§¿å‹¢ ({req_time}ç§’å¾Œé–‹å§‹)", (20, 50), COLOR_TEXT, 40, stroke_width=2)
            
            if coords:
                # åˆ¤å®šé˜²ç¦¦å§¿å‹¢
                l_guard = coords['L_WR'][1] < coords['L_EL'][1]
                r_guard = coords['R_WR'][1] < coords['R_EL'][1]
                
                if l_guard and r_guard:
                    cv2.rectangle(img, (0,0), (w, h), (0, 255, 0), 5)  # ç¶ æ¡†æç¤º
                    
                    if self.guard_start_time == 0:
                        self.guard_start_time = current_time
                    
                    elapsed = current_time - self.guard_start_time
                    remaining = max(0, req_time - elapsed)
                    
                    # é¡¯ç¤ºå€’æ•¸
                    img = self.put_chinese_text(img, f"{remaining:.1f}ç§’", (w//2-50, 100), (0, 255, 255), 50)
                    
                    if elapsed >= req_time:
                        self.state = 'COUNTDOWN'
                        self.start_time = current_time
                        self.guard_start_time = 0
                else:
                    self.guard_start_time = 0  # é‡ç½®è¨ˆæ™‚

        elif self.state == 'COUNTDOWN':
            remaining = 3.0 - (current_time - self.start_time)
            if remaining <= 0:
                self.state = 'STIMULUS'
                self.target = random.choice(['LEFT', 'RIGHT'])
                self.stimulus_time = current_time
                self.max_speed = 0
                self.speed_buffer.clear()
                self.velocity_history.clear()
                self.punch_start_pos = None
                self.punch_end_pos = None
            else:
                # ä¸­å¤®å€’æ•¸
                cx, cy = int(w/2)-20, int(h/2)
                img = self.put_chinese_text(img, f"{int(remaining)+1}", (cx, cy), (0, 255, 255), 100, stroke_width=4)

        elif self.state == 'STIMULUS':
            # é¡¯ç¤ºè¦–è¦ºåˆºæ¿€
            text = "å·¦æ‹³!" if self.target == 'LEFT' else "å³æ‹³!"
            color = COLOR_CYAN if self.target == 'LEFT' else COLOR_RED
            
            cx, cy = int(w/2)-100, int(h/2)
            img = self.put_chinese_text(img, text, (cx, cy), color, 120, stroke_width=6)
            
            # åµæ¸¬å‡ºæ‹³
            if coords and self.prev_landmarks:
                speed = self.calculate_speed_advanced(coords, dt)
                
                # è¨˜éŒ„å‡ºæ‹³é–‹å§‹ä½ç½®
                if self.punch_start_pos is None and speed > 1.0:
                    active_wrist = 'L_WR' if self.target == 'LEFT' else 'R_WR'
                    self.punch_start_pos = coords[active_wrist].copy()
                
                # æ›´æ–°æœ€å¤§é€Ÿåº¦
                if speed > self.max_speed:
                    self.max_speed = speed
                
                # è§¸ç™¼æ¢ä»¶ï¼šé€Ÿåº¦å³°å€¼ + æ‰‹è‡‚ä¼¸ç›´
                if speed > 4.0 and self.detect_punch_movement(coords):
                    self.state = 'RESULT'
                    reaction_time = (current_time - self.stimulus_time) * 1000
                    
                    # è¨˜éŒ„å‡ºæ‹³çµæŸä½ç½®
                    active_wrist = 'L_WR' if self.target == 'LEFT' else 'R_WR'
                    self.punch_end_pos = coords[active_wrist].copy()
                    
                    # è¨ˆç®—æœ€çµ‚é€Ÿåº¦ï¼ˆä½¿ç”¨å³°å€¼é€Ÿåº¦ï¼‰
                    if len(self.velocity_history) > 3:
                        final_speed = np.max(self.velocity_history[-5:])  # ä½¿ç”¨æœ€è¿‘5å¹€çš„æœ€å¤§å€¼
                    else:
                        final_speed = self.max_speed
                    
                    # æ›´æ–°æœ€å¾Œçµæœ
                    self.last_result['reaction'] = reaction_time
                    self.last_result['speed'] = final_speed
                    self.last_result['hand'] = self.target
                    
                    # è©•åƒ¹é‚è¼¯
                    if reaction_time < 120: 
                        self.last_result['rating'] = "ğŸ‘‘ é ‚å°–"
                    elif reaction_time < 250: 
                        self.last_result['rating'] = "ğŸ”¥ å„ªç•°"
                    else: 
                        self.last_result['rating'] = "ğŸ˜ ä¸€èˆ¬"
                    
                    if final_speed > 13: 
                        self.last_result['speed_rating'] = "ğŸ’ª è·æ¥­ç´š"
                    elif final_speed > 9: 
                        self.last_result['speed_rating'] = "ğŸ† é¸æ‰‹ç´š"
                    else: 
                        self.last_result['speed_rating'] = "ğŸƒ æ¥­é¤˜"
                    
                    # è¨˜éŒ„åˆ°æ­·å²æ•¸æ“š
                    if self.target == 'LEFT':
                        self.left_history["reaction"].append(reaction_time)
                        self.left_history["speed"].append(final_speed)
                    else:
                        self.right_history["reaction"].append(reaction_time)
                        self.right_history["speed"].append(final_speed)
                    
                    self.current_test += 1
                    self.feedback_end_time = current_time + 2.5  # é¡¯ç¤ºçµæœ2.5ç§’

        elif self.state == 'RESULT':
            # é¡¯ç¤ºå–®æ¬¡çµæœ
            rt = self.last_result['reaction']
            sp = self.last_result['speed']
            hand = self.last_result['hand']
            
            # ç¹ªè£½çµæœé¢æ¿
            overlay = img.copy()
            cv2.rectangle(overlay, (50, h-250), (450, h-50), (0,0,0), -1)
            img = cv2.addWeighted(overlay, 0.7, img, 0.3, 0)
            
            hand_color = COLOR_CYAN if hand == 'LEFT' else COLOR_RED
            hand_text = "å·¦æ‹³" if hand == 'LEFT' else "å³æ‹³"
            
            img = self.put_chinese_text(img, f"{hand_text} çµæœ", (70, h-220), hand_color, 35)
            img = self.put_chinese_text(img, f"åæ‡‰: {rt:.0f} ms", (70, h-180), (255, 255, 255), 30)
            img = self.put_chinese_text(img, f"è©•åƒ¹: {self.last_result['rating']}", (70, h-145), hand_color, 30)
            img = self.put_chinese_text(img, f"æ‹³é€Ÿ: {sp:.1f} m/s", (70, h-110), (255, 255, 255), 30)
            img = self.put_chinese_text(img, f"ç­‰ç´š: {self.last_result['speed_rating']}", (70, h-75), hand_color, 30)
            
            # é¡¯ç¤ºä¸‹ä¸€å€‹æç¤º
            if self.current_test < self.total_tests:
                next_text = f"æº–å‚™ä¸‹ä¸€æ‹³ ({2 if self.current_test > 0 else 3}ç§’é å‚™)"
                img = self.put_chinese_text(img, next_text, (w//2-200, 150), (255, 255, 0), 40)
            
            if current_time > self.feedback_end_time:
                if self.current_test >= self.total_tests:
                    self.calculate_summary()
                    self.state = 'SUMMARY'
                else:
                    self.state = 'WAIT_GUARD'
                    self.guard_start_time = 0

        elif self.state == 'SUMMARY':
            # è¨ˆç®—ä¸¦é¡¯ç¤ºæœ€çµ‚çµæœ
            self.display_summary(img, w, h)

        # æ›´æ–°ä¸Šä¸€å¹€åº§æ¨™
        self.prev_landmarks = coords
        return img

    def calculate_summary(self):
        """ è¨ˆç®—æœ€çµ‚çµ±è¨ˆæ•¸æ“š """
        self.test_completed = True
        
        # è¨ˆç®—å¹³å‡å€¼
        if self.left_history["reaction"]:
            self.summary_data["left_avg_reaction"] = np.mean(self.left_history["reaction"])
            self.summary_data["left_avg_speed"] = np.mean(self.left_history["speed"])
        
        if self.right_history["reaction"]:
            self.summary_data["right_avg_reaction"] = np.mean(self.right_history["reaction"])
            self.summary_data["right_avg_speed"] = np.mean(self.right_history["speed"])
        
        # è©•åƒ¹é‚è¼¯
        def get_rating(reaction, speed):
            rating = []
            if reaction < 150:
                rating.append("é ‚å°–åæ‡‰")
            elif reaction < 280:
                rating.append("è‰¯å¥½åæ‡‰")
            else:
                rating.append("æ™®é€šåæ‡‰")
                
            if speed > 12:
                rating.append("è·æ¥­æ‹³é€Ÿ")
            elif speed > 8:
                rating.append("é¸æ‰‹æ‹³é€Ÿ")
            else:
                rating.append("æ¥­é¤˜æ‹³é€Ÿ")
                
            return " | ".join(rating)
        
        # å·¦å³æ‰‹è©•åƒ¹
        if self.left_history["reaction"]:
            self.summary_data["left_rating"] = get_rating(
                self.summary_data["left_avg_reaction"], 
                self.summary_data["left_avg_speed"]
            )
        
        if self.right_history["reaction"]:
            self.summary_data["right_rating"] = get_rating(
                self.summary_data["right_avg_reaction"], 
                self.summary_data["right_avg_speed"]
            )
        
        # æ•´é«”è©•åƒ¹
        all_reactions = self.left_history["reaction"] + self.right_history["reaction"]
        all_speeds = self.left_history["speed"] + self.right_history["speed"]
        
        if all_reactions:
            avg_reaction = np.mean(all_reactions)
            avg_speed = np.mean(all_speeds)
            
            if avg_reaction < 160 and avg_speed > 10:
                self.summary_data["overall_rating"] = "ğŸ¯ å„ªç§€æ‹³æ“Šæ‰‹æ½›è³ª"
            elif avg_reaction < 200 and avg_speed > 7:
                self.summary_data["overall_rating"] = "â­ è‰¯å¥½é‹å‹•èƒ½åŠ›"
            else:
                self.summary_data["overall_rating"] = "ğŸ’ª æŒçºŒç·´ç¿’å¯é€²æ­¥"

    def display_summary(self, img, w, h):
        """ é¡¯ç¤ºæœ€çµ‚çµæœé¢æ¿ """
        # åŠé€æ˜èƒŒæ™¯
        overlay = img.copy()
        cv2.rectangle(overlay, (0, 0), (w, h), (0, 0, 0), -1)
        img = cv2.addWeighted(overlay, 0.8, img, 0.2, 0)
        
        # æ¨™é¡Œ
        img = self.put_chinese_text(img, "ğŸ¯ æ¸¬è©¦å®Œæˆï¼", (w//2-150, 100), (255, 255, 0), 60, stroke_width=3)
        
        # å·¦æ‹³çµæœ
        left_y = 200
        if self.left_history["reaction"]:
            img = self.put_chinese_text(img, "ğŸ¥Š å·¦æ‹³çµ±è¨ˆ", (w//4-100, left_y), COLOR_CYAN, 45)
            img = self.put_chinese_text(img, f"å¹³å‡åæ‡‰: {self.summary_data['left_avg_reaction']:.0f} ms", 
                                       (w//4-150, left_y+60), (255, 255, 255), 35)
            img = self.put_chinese_text(img, f"å¹³å‡æ‹³é€Ÿ: {self.summary_data['left_avg_speed']:.1f} m/s", 
                                       (w//4-150, left_y+110), (255, 255, 255), 35)
            img = self.put_chinese_text(img, f"è©•åƒ¹: {self.summary_data['left_rating']}", 
                                       (w//4-150, left_y+160), COLOR_CYAN, 30)
        else:
            img = self.put_chinese_text(img, "å·¦æ‹³: æœªæ¸¬è©¦", (w//4-100, left_y), (100, 100, 100), 40)
        
        # å³æ‹³çµæœ
        right_y = 200
        if self.right_history["reaction"]:
            img = self.put_chinese_text(img, "ğŸ¥Š å³æ‹³çµ±è¨ˆ", (3*w//4-100, right_y), COLOR_RED, 45)
            img = self.put_chinese_text(img, f"å¹³å‡åæ‡‰: {self.summary_data['right_avg_reaction']:.0f} ms", 
                                       (3*w//4-150, right_y+60), (255, 255, 255), 35)
            img = self.put_chinese_text(img, f"å¹³å‡æ‹³é€Ÿ: {self.summary_data['right_avg_speed']:.1f} m/s", 
                                       (3*w//4-150, right_y+110), (255, 255, 255), 35)
            img = self.put_chinese_text(img, f"è©•åƒ¹: {self.summary_data['right_rating']}", 
                                       (3*w//4-150, right_y+160), COLOR_RED, 30)
        else:
            img = self.put_chinese_text(img, "å³æ‹³: æœªæ¸¬è©¦", (3*w//4-100, right_y), (100, 100, 100), 40)
        
        # æ•´é«”è©•åƒ¹
        if self.summary_data["overall_rating"]:
            img = self.put_chinese_text(img, "ğŸ“‹ æ•´é«”è©•åƒ¹", (w//2-100, h-250), (255, 255, 255), 50)
            img = self.put_chinese_text(img, self.summary_data["overall_rating"], 
                                       (w//2-200, h-180), (0, 255, 255), 40)
        
        # æ“ä½œæç¤º
        img = self.put_chinese_text(img, "è«‹æŸ¥çœ‹å³å´é¢æ¿é¸æ“‡ä¸‹ä¸€æ­¥", (w//2-200, h-80), (200, 200, 255), 30)

# ================= Streamlit ä»‹é¢ =================
def main():
    st.title("ğŸ¥Š æ‹³æ“Šåæ‡‰æ¸¬è©¦ v26 (10æ¬¡æ¸¬é©—ç‰ˆ)")
    
    # åˆå§‹åŒ–session state
    if 'test_started' not in st.session_state:
        st.session_state.test_started = False
    if 'test_completed' not in st.session_state:
        st.session_state.test_completed = False
    if 'restart_flag' not in st.session_state:
        st.session_state.restart_flag = False
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        # WebRTC ä¸²æµè¨­å®š
        rtc_configuration = RTCConfiguration(
            {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}
        )
        
        webrtc_streamer(
            key="boxing-pro-advanced",
            mode=WebRtcMode.SENDRECV,
            rtc_configuration=rtc_configuration,
            video_processor_factory=VideoProcessor,
            media_stream_constraints={"video": True, "audio": False},
            async_processing=True,
        )
    
    with col2:
        st.header("ğŸ“Š æ¸¬è©¦æ§åˆ¶é¢æ¿")
        
        if not st.session_state.test_started:
            if st.button("ğŸš€ é–‹å§‹10æ¬¡æ¸¬é©—", use_container_width=True, type="primary"):
                st.session_state.test_started = True
                st.session_state.test_completed = False
                st.session_state.restart_flag = True
                st.rerun()
        
        st.divider()
        
        if st.session_state.test_started:
            st.subheader("æ¸¬è©¦èªªæ˜")
            st.markdown("""
            **æ¸¬è©¦æµç¨‹:**
            1. ç¬¬1æ¬¡: ç¶­æŒé å‚™å§¿å‹¢ **3ç§’**
            2. ç¬¬2-10æ¬¡: ç¶­æŒé å‚™å§¿å‹¢ **2ç§’**
            3. çœ‹åˆ°æ–‡å­—æç¤ºå¾Œç«‹å³å‡ºæ‹³
            4. å®Œæˆ10æ¬¡å¾Œé¡¯ç¤ºçµ±è¨ˆçµæœ
            """)
            
            st.divider()
            
            if st.session_state.test_completed:
                st.success("âœ… æ¸¬è©¦å·²å®Œæˆï¼")
                
                col_restart, col_exit = st.columns(2)
                with col_restart:
                    if st.button("ğŸ”„ é‡æ–°æ¸¬é©—", use_container_width=True):
                        st.session_state.test_started = True
                        st.session_state.test_completed = False
                        st.session_state.restart_flag = True
                        st.rerun()
                
                with col_exit:
                    if st.button("ğŸ çµæŸæ¸¬é©—", use_container_width=True):
                        st.session_state.test_started = False
                        st.session_state.test_completed = False
                        st.rerun()
            
            st.divider()
            st.markdown("### ğŸ¯ è©•åƒ¹æ¨™æº–")
            st.caption("**åæ‡‰æ™‚é–“:**")
            st.caption("- <150ms: é ‚å°–åæ‡‰")
            st.caption("- 150-280ms: è‰¯å¥½åæ‡‰")
            st.caption("- >280ms: æ™®é€šåæ‡‰")
            
            st.caption("**å‡ºæ‹³é€Ÿåº¦:**")
            st.caption("- >12m/s: è·æ¥­ç´š")
            st.caption("- 8-12m/s: é¸æ‰‹ç´š")
            st.caption("- <8m/s: æ¥­é¤˜ç´š")

class VideoProcessor(VideoTransformerBase):
    def __init__(self):
        self.logic = BoxingAnalystLogic()
        self.last_restart_flag = False
    
    def recv(self, frame):
        try:
            # æª¢æŸ¥æ˜¯å¦éœ€è¦é‡å•Ÿ
            if hasattr(st.session_state, 'restart_flag') and st.session_state.restart_flag != self.last_restart_flag:
                self.logic = BoxingAnalystLogic()  # é‡æ–°åˆå§‹åŒ–é‚è¼¯
                self.last_restart_flag = st.session_state.restart_flag
                st.session_state.restart_flag = False
            
            img = frame.to_ndarray(format="bgr24")
            processed_img = self.logic.process(img)
            
            # æ›´æ–°æ¸¬è©¦å®Œæˆç‹€æ…‹
            if self.logic.test_completed and not st.session_state.test_completed:
                st.session_state.test_completed = True
            
            return av.VideoFrame.from_ndarray(processed_img, format="bgr24")
        except Exception as e:
            print(f"Error: {e}")
            return frame

if __name__ == "__main__":
    main()
