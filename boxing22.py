import cv2
import av
import numpy as np
import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase
import time
import random
import mediapipe as mp

class BoxingAnalystLogic:
    def __init__(self):
        self.mp_pose = mp.solutions.pose
        self.mp_drawing = mp.solutions.drawing_utils
        self.pose = self.mp_pose.Pose(
            min_detection_confidence=0.5, 
            min_tracking_confidence=0.5,
            model_complexity=1
        )
        
        self.state = 'WAIT_GUARD' 
        self.target = None
        self.start_time = 0
        self.wait_until = 0
        self.command_display_until = 0
        
        # æ•¸æ“šçµ±è¨ˆ
        self.last_reaction_time = 0.0
        self.last_velocity = 0.0
        self.record_max_speed = 0.0
        self.reaction_times_list = []
        
        self.prev_landmarks = None
        self.prev_time = 0
        # å‡è¨­ä¸€èˆ¬äººè‚©å¯¬ 0.45 å…¬å°ºï¼Œç”¨ä¾†å°‡åƒç´ /æ­¸ä¸€åŒ–åº§æ¨™è½‰ç‚ºçœŸå¯¦ç±³æ•¸
        self.SHOULDER_WIDTH_M = 0.45 

        # === æ ¸å¿ƒé–€æª»ï¼š3D ç‰©ç†åˆ¤å®šä¿®æ­£ ===
        # 1. æœ€å°é€Ÿåº¦é–€æª» (é˜²æŠ–å‹•)ï¼šé€Ÿåº¦ä½æ–¼ 1.2 m/s ä¸è¦–ç‚ºå‡ºæ‹³ï¼Œè¦–ç‚ºé›œè¨Š
        self.MIN_VELOCITY_THRESHOLD = 1.2 
        
        # 2. Zè»¸ (å‰é€²) è§¸ç™¼é–€æª»ï¼šæ‰‹è…•å¿…é ˆæ¯”è‚©è†€ "æ›´é è¿‘é¡é ­" å¤šå°‘å–®ä½
        # MediaPipe ä¸­ï¼ŒZ è¶Šè² ä»£è¡¨è¶Šé è¿‘é¡é ­
        self.Z_PUNCH_THRESHOLD = 0.2
        
        # 3. æ‰‹è‡‚ä¼¸ç›´è§’åº¦
        self.ARM_ANGLE_THRESHOLD = 100 

        # æ­¸ä½åˆ¤å®š (å¯¬é¬†)
        self.RETRACTION_THRESHOLD = 0.25
        
        self.current_intensity = 0.0

    def calculate_angle(self, a, b, c):
        # é€™è£¡åªç®— 2D æŠ•å½±è§’åº¦ä¾›åƒè€ƒï¼Œå› ç‚ºæ‰‹è‚˜æ‰“ç›´ä¸»è¦çœ‹é€™è£¡
        a = np.array([a.x, a.y])
        b = np.array([b.x, b.y])
        c = np.array([c.x, c.y])
        radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
        angle = np.abs(radians*180.0/np.pi)
        return 360-angle if angle > 180.0 else angle

    def calculate_3d_velocity(self, curr, prev, scale, dt):
        """ è¨ˆç®— XYZ ä¸‰ç¶­é€Ÿåº¦å‘é‡ """
        if dt <= 0: return 0
        
        dx = curr.x - prev.x
        dy = curr.y - prev.y
        # MediaPipe çš„ Z åº§æ¨™åœ¨æ­¸ä¸€åŒ–ç©ºé–“ä¸­ï¼Œå¤§è‡´èˆ‡ X çš„å¯¬åº¦æ¯”ä¾‹é¡ä¼¼
        # ä½† Z è®ŠåŒ–é€šå¸¸è¼ƒæ•æ„Ÿï¼Œæˆ‘å€‘ç›´æ¥ç´å…¥è¨ˆç®—
        dz = curr.z - prev.z 
        
        # 3D è·é›¢ (Euclidean distance)
        dist_3d = np.sqrt(dx**2 + dy**2 + dz**2)
        
        # è½‰æ›ç‚ºå…¬å°º/ç§’
        velocity = (dist_3d * scale) / dt
        return velocity

    def draw_feedback_bar(self, image, h, w):
        """ å³ä¸‹è§’ï¼šé¡¯ç¤ºå³æ™‚é€Ÿåº¦å¼·åº¦ (éæ¿¾é›œè¨Šå¾Œ) """
        bar_w, bar_h = 240, 25
        start_x, start_y = w - 260, h - 60
        
        # èƒŒæ™¯
        cv2.rectangle(image, (start_x, start_y), (start_x + bar_w, start_y + bar_h), (50, 50, 50), -1)
        
        # å¼·åº¦ï¼šåŸºæ–¼ç•¶å‰é€Ÿåº¦ / é æœŸæœ€å¤§é€Ÿåº¦ (ä¾‹å¦‚ 8 m/s)
        fill_w = int(self.current_intensity * bar_w)
        
        # é¡è‰²é‚è¼¯ï¼šæœªé”æœ€å°é–€æª»ç‚ºç°/ç™½ï¼Œé”åˆ°æ”»æ“Šé€Ÿåº¦ç‚ºç´…
        if self.last_velocity < self.MIN_VELOCITY_THRESHOLD and self.state == 'STIMULUS':
            color = (150, 150, 150) # å™ªéŸ³å€
        elif self.current_intensity < 0.5:
            color = (0, 255, 255)   # é»ƒ (è“„åŠ›)
        else:
            color = (0, 0, 255)     # ç´… (æœ‰æ•ˆæ‰“æ“Š)

        cv2.rectangle(image, (start_x, start_y), (start_x + fill_w, start_y + bar_h), color, -1)
        
        # æ–‡å­—
        txt = f"SPEED: {self.last_velocity:.1f} m/s"
        if self.last_velocity < self.MIN_VELOCITY_THRESHOLD:
             txt += " (NOISE)"
        cv2.putText(image, txt, (start_x, start_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

    def draw_dashboard(self, image, h, w):
        overlay = image.copy()
        cv2.rectangle(overlay, (10, h - 220), (360, h - 10), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, image, 0.3, 0, image)
        
        status_map = {
            'WAIT_GUARD': ("RESET: HANDS UP", (0, 165, 255)),
            'PRE_START': ("READY...", (0, 255, 255)),
            'STIMULUS': ("GO !!!", (0, 0, 255)),
            'RESULT_PENDING': ("GO !!!", (0, 0, 255)),
            'RESULT': ("HIT!", (0, 255, 0))
        }
        text, color = status_map.get(self.state, ("IDLE", (255,255,255)))
        cv2.putText(image, text, (20, h - 185), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)

        r_time = f"{int(self.last_reaction_time)} ms" if self.last_reaction_time > 0 else "---"
        # é€™è£¡é¡¯ç¤ºçš„æ˜¯å‘½ä¸­ç•¶ä¸‹çš„é€Ÿåº¦
        v_speed = f"{self.record_max_speed:.1f} m/s" if self.record_max_speed > 0 else "---"
        
        cv2.putText(image, f"Time: {r_time}", (20, h - 145), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)
        cv2.putText(image, f"Max Spd: {v_speed}", (20, h - 115), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)
        cv2.line(image, (20, h - 100), (340, h - 100), (100, 100, 100), 1)

    def process(self, image):
        image.flags.writeable = False
        results = self.pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        image.flags.writeable = True
        h, w, _ = image.shape
        current_time = time.time()
        
        if results.pose_landmarks:
            landmarks = results.pose_landmarks.landmark
            self.mp_drawing.draw_landmarks(image, results.pose_landmarks, self.mp_pose.POSE_CONNECTIONS)

            # å–å¾—é—œéµé»
            l_sh, r_sh = landmarks[11], landmarks[12]
            l_el, r_el = landmarks[13], landmarks[14]
            l_wr, r_wr = landmarks[15], landmarks[16]
            
            # 1. è¨ˆç®—æ¯”ä¾‹å°º (åƒç´  -> å…¬å°º)
            # é€™è£¡ç”¨ shoulder 2D è·é›¢ç•¶åŸºæº–ï¼Œé›–ç„¶æœ‰ Z è»¸èª¤å·®ï¼Œä½†åšç‚ºç›¸å°åƒè€ƒè¶³å¤ 
            sh_dist_2d = np.sqrt((l_sh.x - r_sh.x)**2 + (l_sh.y - r_sh.y)**2)
            scale = self.SHOULDER_WIDTH_M / sh_dist_2d if sh_dist_2d > 0 else 0

            # 2. è¨ˆç®— 3D ç¬æ™‚é€Ÿåº¦
            curr_v = 0.0
            dt = current_time - self.prev_time
            if self.prev_landmarks and dt > 0:
                l_v = self.calculate_3d_velocity(l_wr, self.prev_landmarks[15], scale, dt)
                r_v = self.calculate_3d_velocity(r_wr, self.prev_landmarks[16], scale, dt)
                curr_v = max(l_v, r_v)
            
            # éæ¿¾ï¼šå¦‚æœé€Ÿåº¦å°æ–¼é–€æª»ï¼Œè¦–ç‚º 0 (å»é™¤ç«™ç«‹æŠ–å‹•)
            display_v = curr_v if curr_v > self.MIN_VELOCITY_THRESHOLD else 0.0
            
            # æ›´æ–°å…¨åŸŸè®Šæ•¸ä¾› UI ä½¿ç”¨
            self.last_velocity = display_v 
            self.current_intensity = min(1.0, display_v / 8.0) # å‡è¨­ 8m/s ç‚ºæ»¿æ ¼

            self.prev_landmarks, self.prev_time = landmarks, current_time
            
            # --- ç‹€æ…‹æ©Ÿ ---
            dist_l_2d = abs(l_wr.x - l_sh.x)
            dist_r_2d = abs(r_wr.x - r_sh.x)

            if self.state == 'WAIT_GUARD':
                # é‡ç½®æœ€å¤§é€Ÿåº¦
                self.record_max_speed = 0.0
                if (dist_l_2d < self.RETRACTION_THRESHOLD) and (dist_r_2d < self.RETRACTION_THRESHOLD):
                    self.state, self.wait_until = 'PRE_START', current_time + random.uniform(1.5, 3.0)
                else:
                    cv2.putText(image, "HANDS UP!", (int(w/2)-100, h-80), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

            elif self.state == 'PRE_START':
                if current_time > self.wait_until:
                    self.state, self.target = 'STIMULUS', random.choice(['LEFT', 'RIGHT'])
                    self.start_time = current_time
                    self.command_display_until = current_time + 1.0
                    self.max_v_temp = 0.0

            if self.state in ['STIMULUS', 'RESULT_PENDING']:
                if current_time <= self.command_display_until:
                    color = (0, 0, 255) if self.target == 'LEFT' else (255, 0, 0)
                    cv2.putText(image, f"{self.target}!", (int(w/2)-120, int(h/2)), cv2.FONT_HERSHEY_SIMPLEX, 5, color, 10)

            if self.state == 'STIMULUS':
                # åªæœ‰åœ¨é€Ÿåº¦è¶…éå™ªéŸ³é–€æª»æ™‚ï¼Œæ‰é–‹å§‹è¨˜éŒ„æœ€å¤§é€Ÿåº¦
                if curr_v > self.MIN_VELOCITY_THRESHOLD:
                    self.max_v_temp = max(self.max_v_temp, curr_v)

                # é–å®šç›®æ¨™æ‰‹
                t_wr = l_wr if self.target == 'LEFT' else r_wr
                t_sh = l_sh if self.target == 'LEFT' else r_sh
                t_el = l_el if self.target == 'LEFT' else r_el
                
                # === åš´æ ¼åˆ¤å®šæ¢ä»¶ (AND é‚è¼¯) ===
                # 1. é€Ÿåº¦å¿…é ˆå¤ å¿« (ä»£è¡¨æ˜¯ punch ä¸æ˜¯ move)
                cond_speed = curr_v > self.MIN_VELOCITY_THRESHOLD
                
                # 2. Z è»¸åˆ¤å®š: æ‰‹è…•å¿…é ˆæ˜é¡¯åœ¨è‚©è†€ "å‰é¢" (Z å€¼æ›´å°)
                # ä¸€èˆ¬é å‚™æ™‚æ‰‹è…• Z ç´„ç­‰æ–¼è‚©è†€ Zï¼Œå‡ºæ‹³æ™‚ Z æœƒè®Šå°
                # æˆ‘å€‘è¨­å®šæ‰‹è…• Z å¿…é ˆæ¯”è‚©è†€ Z å° 0.2 ä»¥ä¸Š (æ•¸å€¼éœ€è¦–ç’°å¢ƒå¾®èª¿)
                cond_z_forward = (t_wr.z < t_sh.z - self.Z_PUNCH_THRESHOLD)
                
                # 3. 2D è¼”åŠ©åˆ¤å®š (é¿å…å®Œå…¨æ²’ä¼¸ç›´)
                t_angle = self.calculate_angle(t_sh, t_el, t_wr)
                cond_extend = t_angle > self.ARM_ANGLE_THRESHOLD

                # åªæœ‰ç•¶ "æœ‰é€Ÿåº¦" ä¸” "å¾€å‰æ‰“(Z)" æ‰ç®—å‘½ä¸­
                if cond_speed and (cond_z_forward or cond_extend):
                    self.last_reaction_time = (current_time - self.start_time) * 1000
                    self.record_max_speed = self.max_v_temp # é–å®šé€™æ‹³çš„æœ€å¤§é€Ÿåº¦
                    self.reaction_times_list.append(self.last_reaction_time)
                    
                    self.state, self.wait_until = 'RESULT_PENDING', self.command_display_until
                
                if (current_time - self.start_time) > 3.0: self.state = 'WAIT_GUARD'

            elif self.state == 'RESULT_PENDING':
                if current_time > self.wait_until:
                    self.state, self.wait_until = 'RESULT', current_time + 2.0

            elif self.state == 'RESULT':
                if current_time > self.wait_until: self.state = 'WAIT_GUARD'
        
        self.draw_dashboard(image, h, w)
        self.draw_feedback_bar(image, h, w)
        return image

class VideoProcessor(VideoTransformerBase):
    def __init__(self): self.logic = BoxingAnalystLogic()
    def recv(self, frame):
        try:
            img = cv2.flip(frame.to_ndarray(format="bgr24"), 1)
            return av.VideoFrame.from_ndarray(self.logic.process(img), format="bgr24")
        except: return frame

def main():
    st.set_page_config(page_title="æ‹³æ“Šåæ‡‰ v17 (3Dç‰©ç†ä¿®æ­£)", layout="wide")
    st.title("ğŸ¥Š æ‹³æ“Šåæ‡‰ - 3D é€Ÿåº¦èˆ‡ Z è»¸åˆ¤å®šç‰ˆ")
    st.sidebar.write("v17 æ›´æ–°é‡é»ï¼š")
    st.sidebar.write("1. ä¿®æ­£ï¼šå¾€é¡é ­æ‰“(Zè»¸)ç¾åœ¨æœ‰é€Ÿåº¦äº†")
    st.sidebar.write("2. ä¿®æ­£ï¼šéæ¿¾èº«é«”æŠ–å‹• (é€Ÿåº¦ < 1.2m/s å¿½ç•¥)")
    st.sidebar.write("3. åˆ¤å®šï¼šå¿…é ˆå…¼å…·ã€Œé€Ÿåº¦ã€èˆ‡ã€Œå‰é€²ã€")
    webrtc_streamer(key="boxing-v17", video_processor_factory=VideoProcessor, 
                    media_stream_constraints={"video": True, "audio": False}, async_processing=True)

if __name__ == "__main__": main()
