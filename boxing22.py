import cv2
import av
import numpy as np
import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, RTCConfiguration, WebRtcMode
import mediapipe as mp
import time
import random
import math
from PIL import ImageFont, ImageDraw, Image

# ================= é…ç½®èˆ‡å¸¸æ•¸ =================
st.set_page_config(page_title="æ‹³æ“Šåæ‡‰ v25 (Webcam Pro)", layout="wide", page_icon="ğŸ¥Š")

# é¡è‰²å®šç¾© (B, G, R)
COLOR_CYAN = (255, 255, 0)    # å·¦æ‹³æç¤ºè‰² (OpenCVæ˜¯BGR)
COLOR_RED = (50, 50, 255)     # å³æ‹³æç¤ºè‰²
COLOR_TEXT = (255, 255, 255)
COLOR_STROKE = (0, 0, 0)

# ç‰©ç†å¸¸æ•¸
SHOULDER_WIDTH_M = 0.45  # å‡è¨­ä¸€èˆ¬äººè‚©å¯¬ 0.45 å…¬å°º (ç”¨æ–¼åƒç´ è½‰ç±³)

class BoxingAnalystLogic:
    def __init__(self):
        # MediaPipe åˆå§‹åŒ–
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(
            min_detection_confidence=0.6,
            min_tracking_confidence=0.6,
            model_complexity=1
        )
        
        # ç‹€æ…‹æ©Ÿ: WAIT_GUARD -> COUNTDOWN -> STIMULUS -> PUNCHING -> RESULT
        self.state = 'WAIT_GUARD'
        self.start_time = 0
        self.stimulus_time = 0
        self.target = None # 'LEFT' or 'RIGHT'
        self.feedback_end_time = 0
        
        # ç‰©ç†è¨ˆç®—è®Šæ•¸
        self.prev_landmarks = None
        self.prev_time = 0
        self.max_speed = 0.0
        self.punch_detected_time = 0
        
        # æ­·å²æ•¸æ“š
        self.reaction_history = []
        self.speed_history = []
        self.last_result = {"reaction": 0, "speed": 0, "rating": "", "speed_rating": ""}

        # å­—å‹åŠ è¼‰
        self.font_path = "font.ttf"
        self.use_chinese = False
        try:
            ImageFont.truetype(self.font_path, 20)
            self.use_chinese = True
        except:
            print("æœªæ‰¾åˆ°å­—å‹æª”ï¼Œå°‡ä½¿ç”¨é è¨­å­—é«”")

    def put_chinese_text(self, img, text, pos, color, size=30, stroke_width=0):
        """ ä½¿ç”¨ PIL ç¹ªè£½é«˜å“è³ªä¸­æ–‡ (å«æé‚Š) """
        if not self.use_chinese:
            cv2.putText(img, text, pos, cv2.FONT_HERSHEY_SIMPLEX, size/30, color, 2)
            return img
            
        img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(img_pil)
        try:
            font = ImageFont.truetype(self.font_path, size)
            # è½‰æ›é¡è‰² BGR -> RGB (PIL ä½¿ç”¨ RGB)
            pil_color = (color[2], color[1], color[0])
            draw.text(pos, text, font=font, fill=pil_color, stroke_width=stroke_width, stroke_fill=(0,0,0))
        except Exception as e:
            print(f"Font Error: {e}")
            
        return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

    def get_landmarks(self, results, width, height):
        """ è§£æé—œéµé»åº§æ¨™ """
        if not results.pose_landmarks:
            return None
            
        lm = results.pose_landmarks.landmark
        
        # æå–é—œéµé» (11,12è‚©è†€; 13,14æ‰‹è‚˜; 15,16æ‰‹è…•)
        coords = {}
        key_points = {
            'L_SH': 11, 'R_SH': 12,
            'L_EL': 13, 'R_EL': 14,
            'L_WR': 15, 'R_WR': 16,
            'NOSE': 0
        }
        
        for name, idx in key_points.items():
            # x, y æ˜¯åƒç´ åº§æ¨™, z æ˜¯ç›¸å°æ·±åº¦
            coords[name] = np.array([lm[idx].x * width, lm[idx].y * height, lm[idx].z * width])
            
        return coords

    def calculate_speed(self, current_coords, dt):
        """ è¨ˆç®—æ‹³é€Ÿ (m/s) """
        if not self.prev_landmarks or dt <= 0:
            return 0.0
            
        # 1. è¨ˆç®—åƒç´ æ¯”ä¾‹å°º (Pixels per Meter)
        # å–å¾—ç•¶å‰è‚©è†€åƒç´ è·é›¢
        shoulder_dist_px = np.linalg.norm(current_coords['L_SH'][:2] - current_coords['R_SH'][:2])
        if shoulder_dist_px < 10: return 0.0 # é¿å…é™¤ä»¥é›¶æˆ–é›œè¨Š
        
        pixels_per_meter = shoulder_dist_px / SHOULDER_WIDTH_M
        
        # 2. åˆ¤æ–·å‡ºæ‹³æ‰‹
        active_wrist = 'L_WR' if self.target == 'LEFT' else 'R_WR'
        
        # 3. è¨ˆç®—æ‰‹è…•ä½ç§» (3Dè·é›¢)
        curr_pos = current_coords[active_wrist]
        prev_pos = self.prev_landmarks[active_wrist]
        dist_px = np.linalg.norm(curr_pos - prev_pos)
        
        # 4. è½‰æ›ç‚ºçœŸå¯¦é€Ÿåº¦
        speed_mps = (dist_px / pixels_per_meter) / dt
        
        # éæ¿¾é›œè¨Š (äººé¡æ¥µé™ç´„ 15-20 m/sï¼Œå¤§æ–¼ 30 è¦–ç‚ºèª¤åˆ¤)
        if speed_mps > 30: return 0.0
        
        return speed_mps

    def process(self, img):
        # 1. å½±åƒå‰è™•ç†
        img = cv2.flip(img, 1) # é¡åƒ
        h, w, _ = img.shape
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = self.pose.process(img_rgb)
        
        current_time = time.time()
        dt = current_time - self.prev_time
        self.prev_time = current_time
        
        coords = self.get_landmarks(results, w, h)
        
        # ç¹ªè£½éª¨æ¶ (è¦–è¦ºå›é¥‹)
        if results.pose_landmarks:
            mp.solutions.drawing_utils.draw_landmarks(
                img, results.pose_landmarks, self.mp_pose.POSE_CONNECTIONS)

        # ç‹€æ…‹æ©Ÿé‚è¼¯
        if self.state == 'WAIT_GUARD':
            # é¡¯ç¤ºæŒ‡å¼•
            img = self.put_chinese_text(img, "è«‹æ“ºå‡ºæ ¼é¬¥å§¿å‹¢ (é›™æ‰‹èˆ‰èµ·)", (20, 50), COLOR_TEXT, 40, stroke_width=2)
            
            if coords:
                # ç°¡å–®åˆ¤å®šï¼šæ‰‹è…•é«˜æ–¼æ‰‹è‚˜
                l_guard = coords['L_WR'][1] < coords['L_EL'][1]
                r_guard = coords['R_WR'][1] < coords['R_EL'][1]
                
                if l_guard and r_guard:
                    cv2.rectangle(img, (0,0), (w, h), (0, 255, 0), 5) # ç¶ æ¡†æç¤º
                    if current_time - self.start_time > 1.0: # ç¶­æŒ1ç§’
                        self.state = 'COUNTDOWN'
                        self.start_time = current_time
                else:
                    self.start_time = current_time # é‡ç½®è¨ˆæ™‚

        elif self.state == 'COUNTDOWN':
            remaining = 3.0 - (current_time - self.start_time)
            if remaining <= 0:
                self.state = 'STIMULUS'
                self.target = random.choice(['LEFT', 'RIGHT'])
                self.stimulus_time = current_time
                self.max_speed = 0
            else:
                # ä¸­å¤®å€’æ•¸
                cx, cy = int(w/2), int(h/2)
                img = self.put_chinese_text(img, f"{int(remaining)+1}", (cx-20, cy), (0, 255, 255), 100, stroke_width=4)

        elif self.state == 'STIMULUS':
            # é¡¯ç¤ºè¦–è¦ºåˆºæ¿€ (v23 é¢¨æ ¼)
            text = "å·¦æ‹³!" if self.target == 'LEFT' else "å³æ‹³!"
            color = COLOR_CYAN if self.target == 'LEFT' else COLOR_RED
            
            cx, cy = int(w/2)-100, int(h/2)
            img = self.put_chinese_text(img, text, (cx, cy), color, 120, stroke_width=6)
            
            # åµæ¸¬å‡ºæ‹³
            if coords and self.prev_landmarks:
                speed = self.calculate_speed(coords, dt)
                if speed > self.max_speed: self.max_speed = speed
                
                # è§¸ç™¼æ¢ä»¶ï¼šé€Ÿåº¦å¤§æ–¼é–¾å€¼ ä¸” æ‰‹ä¼¸ç›´
                # é€™è£¡ç°¡åŒ–ï¼šåªè¦é€Ÿåº¦è¶…é 3.5 m/s ä¸”æ–¹å‘æ­£ç¢º
                if speed > 3.5:
                    self.state = 'RESULT'
                    reaction_time = (current_time - self.stimulus_time) * 1000
                    self.last_result['reaction'] = reaction_time
                    self.last_result['speed'] = self.max_speed
                    self.feedback_end_time = current_time + 3.0
                    
                    # è¨˜éŒ„æ•¸æ“š
                    self.reaction_history.append(reaction_time)
                    self.speed_history.append(self.max_speed)

        elif self.state == 'RESULT':
            # é¡¯ç¤ºçµæœ (v23 è©•åƒ¹æ¨™æº–)
            rt = self.last_result['reaction']
            sp = self.last_result['speed']
            
            # è©•åƒ¹é‚è¼¯
            if rt < 120: r_txt, r_col = "ğŸ‘‘ é ‚å°–", COLOR_CYAN
            elif rt < 250: r_txt, r_col = "ğŸ”¥ å„ªç•°", (0, 255, 0)
            else: r_txt, r_col = "ğŸ˜ ä¸€èˆ¬", (200, 200, 200)
            
            if sp > 13: s_txt, s_col = "ğŸ’ª è·æ¥­ç´š", COLOR_RED
            elif sp > 9: s_txt, s_col = "ğŸ† é¸æ‰‹ç´š", (0, 165, 255) # Orange
            else: s_txt, s_col = "ğŸƒ æ¥­é¤˜", (255, 255, 0)

            # ç¹ªè£½çµæœé¢æ¿
            overlay = img.copy()
            cv2.rectangle(overlay, (50, h-250), (400, h-50), (0,0,0), -1)
            img = cv2.addWeighted(overlay, 0.7, img, 0.3, 0)
            
            img = self.put_chinese_text(img, f"åæ‡‰: {rt:.0f} ms", (70, h-200), (255, 255, 255), 30)
            img = self.put_chinese_text(img, f"è©•åƒ¹: {r_txt}", (70, h-160), r_col, 30)
            img = self.put_chinese_text(img, f"æ‹³é€Ÿ: {sp:.1f} m/s", (70, h-110), (255, 255, 255), 30)
            img = self.put_chinese_text(img, f"ç­‰ç´š: {s_txt}", (70, h-70), s_col, 30)
            
            if current_time > self.feedback_end_time:
                self.state = 'WAIT_GUARD'

        # æ›´æ–°ä¸Šä¸€å¹€åº§æ¨™
        self.prev_landmarks = coords
        return img

# ================= Streamlit ä»‹é¢ =================
def main():
    st.title("ğŸ¥Š æ‹³æ“Šåæ‡‰æ¸¬è©¦ v25 (Webcam çœŸäººç‰ˆ)")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        # WebRTC ä¸²æµè¨­å®š
        rtc_configuration = RTCConfiguration(
            {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}
        )
        
        webrtc_streamer(
            key="boxing-pro",
            mode=WebRtcMode.SENDRECV,
            rtc_configuration=rtc_configuration,
            video_processor_factory=VideoProcessor,
            media_stream_constraints={"video": True, "audio": False},
            async_processing=True,
        )

    with col2:
        st.header("ğŸ“Š æ¸¬è©¦æ•¸æ“š")
        st.markdown("""
        **ä½¿ç”¨èªªæ˜:**
        1. å…è¨±ç€è¦½å™¨ä½¿ç”¨é¡é ­ã€‚
        2. é€€å¾Œè‡³èƒ½çœ‹åˆ° **è…°éƒ¨ä»¥ä¸Š** çš„ä½ç½®ã€‚
        3. **èˆ‰èµ·é›™æ‰‹** (é«˜æ–¼æ‰‹è‚˜) é–‹å§‹æ¸¬è©¦ã€‚
        4. çœ‹åˆ° **æ–‡å­—æç¤º** å¾Œå…¨åŠ›å‡ºæ‹³ï¼
        """)
        st.divider()
        st.markdown("### è©•åƒ¹æ¨™æº–")
        st.caption("åæ‡‰æ™‚é–“: <120ms (é ‚å°–), <250ms (å„ªç•°)")
        st.caption("å‡ºæ‹³é€Ÿåº¦: >13m/s (è·æ¥­), >9m/s (é¸æ‰‹)")

class VideoProcessor(VideoTransformerBase):
    def __init__(self):
        self.logic = BoxingAnalystLogic()
        
    def recv(self, frame):
        try:
            img = frame.to_ndarray(format="bgr24")
            # è™•ç†å½±åƒä¸¦å›å‚³
            processed_img = self.logic.process(img)
            return av.VideoFrame.from_ndarray(processed_img, format="bgr24")
        except Exception as e:
            print(f"Error: {e}")
            return frame

if __name__ == "__main__":
    main()
