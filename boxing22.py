import cv2
import av
import numpy as np
import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase
import time
import random
import mediapipe as mp

# ==========================================
# é‚è¼¯æ ¸å¿ƒé¡åˆ¥
# ==========================================
class BoxingAnalystLogic:
    def __init__(self):
        # MediaPipe è¨­å®š
        self.mp_pose = mp.solutions.pose
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_drawing_styles = mp.solutions.drawing_styles
        
        self.pose = self.mp_pose.Pose(
            min_detection_confidence=0.5, 
            min_tracking_confidence=0.5,
            model_complexity=1
        )
        
        # ç‹€æ…‹ç®¡ç†
        self.state = 'WAIT_GUARD' # WAIT_GUARD, PRE_START, STIMULUS, RESULT
        self.target = None
        self.start_time = 0
        self.wait_until = 0
        
        # æ•¸æ“šè¨˜éŒ„
        self.last_reaction_time = 0.0 # å–®ä½: ms
        self.last_velocity = 0.0      # å–®ä½: m/s
        self.last_hand = "None"
        
        # é€Ÿåº¦è¨ˆç®—
        self.prev_landmarks = None
        self.prev_time = 0
        self.SHOULDER_WIDTH_M = 0.45 

        # Debug: è¨˜éŒ„ç›®å‰çš„ä¼¸å±•ç¨‹åº¦
        self.current_extension = 0.0
        
        # è¨­å®šåˆ¤å®šé–€æª» (è¶Šå°è¶Šå®¹æ˜“è§¸ç™¼)
        self.EXTENSION_THRESHOLD = 0.12 
        # è¨­å®šæœ€å¤§é¡¯ç¤ºç¯„åœ (ç”¨æ–¼ç¹ªè£½é€²åº¦æ¢æ¯”ä¾‹)
        self.MAX_EXTENSION_DISPLAY = 0.3

    def calculate_velocity(self, landmark, prev_landmark, scale, dt):
        if dt <= 0: return 0
        dx = landmark.x - prev_landmark.x
        dy = landmark.y - prev_landmark.y
        dz = landmark.z - prev_landmark.z
        dist_px = np.sqrt(dx**2 + dy**2 + dz**2)
        return (dist_px * scale) / dt

    def draw_dashboard(self, image, h, w):
        """ ç¹ªè£½å¸¸é§å„€è¡¨æ¿ """
        # 1. å·¦ä¸‹è§’åŠé€æ˜é»‘åº•
        overlay = image.copy()
        top_y = max(0, h - 180)
        cv2.rectangle(overlay, (10, top_y), (300, h - 10), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.6, image, 0.4, 0, image)
        
        # 2. é¡¯ç¤ºå›ºå®šæ¨™ç±¤
        font = cv2.FONT_HERSHEY_SIMPLEX
        white = (255, 255, 255)
        
        # ç‹€æ…‹é¡¯ç¤º
        status_text = "READY"
        if self.state == 'WAIT_GUARD': status_text = "HANDS UP!"
        elif self.state == 'PRE_START': status_text = "WAIT..."
        elif self.state == 'STIMULUS': status_text = "PUNCH!"
        elif self.state == 'RESULT': status_text = "RESULT"
        
        cv2.putText(image, f"STATE: {status_text}", (20, h - 140), font, 0.7, (0, 255, 255), 2)

        # æ•¸æ“šé¡¯ç¤º (è½‰ç‚º ms æ•´æ•¸é¡¯ç¤º)
        if self.last_reaction_time > 0:
            r_time_str = f"{int(self.last_reaction_time)} ms" 
        else:
            r_time_str = "---"
            
        vel_str = f"{self.last_velocity:.1f} m/s" if self.last_velocity > 0 else "---"
        
        cv2.putText(image, f"Time: {r_time_str}", (20, h - 100), font, 0.9, white, 2)
        cv2.putText(image, f"Speed: {vel_str}", (20, h - 60), font, 0.8, white, 2)
        cv2.putText(image, f"Last: {self.last_hand}", (20, h - 25), font, 0.7, (200, 200, 200), 1)

        # 3. ç¹ªè£½ä¼¸å±•åŠ›åº¦æ¢ (Extension Check)
        bar_x = 320
        bar_w = 200
        bar_h = 20
        bar_y = h - 40
        
        # å¤–æ¡†
        cv2.rectangle(image, (bar_x, bar_y), (bar_x + bar_w, bar_y + bar_h), (255,255,255), 2)
        
        # é–¾å€¼ç·š (ç´…ç·š) - æ ¹æ“š 0.12 è¨ˆç®—ä½ç½®
        threshold_ratio = self.EXTENSION_THRESHOLD / self.MAX_EXTENSION_DISPLAY
        threshold_x = int(bar_x + threshold_ratio * bar_w)
        
        # ç•«ç´…ç·š
        cv2.line(image, (threshold_x, bar_y - 5), (threshold_x, bar_y + bar_h + 5), (0,0,255), 2)
        
        # å¡«å……æ¢ (æ ¹æ“šç›®å‰ä¼¸å±•ç¨‹åº¦)
        fill_ratio = self.current_extension / self.MAX_EXTENSION_DISPLAY
        fill_len = int(fill_ratio * bar_w)
        fill_len = max(0, min(fill_len, bar_w))
        
        # é¡è‰²é‚è¼¯ï¼šè¶…éé–¾å€¼è®Šç¶ è‰²ï¼Œå¦å‰‡é»ƒè‰²
        color = (0, 255, 0) if self.current_extension > self.EXTENSION_THRESHOLD else (0, 255, 255)
        cv2.rectangle(image, (bar_x, bar_y), (bar_x + fill_len, bar_y + bar_h), color, -1)
        
        # æ–‡å­—æ¨™ç¤º
        cv2.putText(image, "Reach Check", (bar_x, bar_y - 10), font, 0.5, white, 1)

    def process(self, image):
        image.flags.writeable = False
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = self.pose.process(image_rgb)
        
        image.flags.writeable = True
        image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
        h, w, c = image.shape
        
        current_time = time.time()
        dt = current_time - self.prev_time
        self.prev_time = current_time

        # ç¹ªè£½å„€è¡¨æ¿
        self.draw_dashboard(image, h, w)

        if results.pose_landmarks:
            landmarks = results.pose_landmarks.landmark
            
            # ç•«éª¨æ¶
            self.mp_drawing.draw_landmarks(
                image, results.pose_landmarks, self.mp_pose.POSE_CONNECTIONS,
                landmark_drawing_spec=self.mp_drawing_styles.get_default_pose_landmarks_style()
            )

            # ç²å–é—œéµé»
            left_shoulder = landmarks[11]
            right_shoulder = landmarks[12]
            left_wrist = landmarks[15]
            right_wrist = landmarks[16]
            
            # è¨ˆç®—ç›®å‰çš„ã€Œæ©«å‘ä¼¸å±•è·é›¢ã€ (çµ•å°å€¼)
            # é€™æ±ºå®šäº†ä¸‹æ–¹çš„ç¶ è‰²æ¢æœ‰å¤šé•·
            dist_l = abs(left_wrist.x - left_shoulder.x)
            dist_r = abs(right_wrist.x - right_shoulder.x)
            self.current_extension = max(dist_l, dist_r)

            # è¨ˆç®—æ¯”ä¾‹å°º
            shoulder_dist = np.sqrt((left_shoulder.x - right_shoulder.x)**2 + 
                                    (left_shoulder.y - right_shoulder.y)**2)
            scale_factor = self.SHOULDER_WIDTH_M / shoulder_dist if shoulder_dist > 0 else 0

            # è¨ˆç®—é€Ÿåº¦
            left_v = 0
            right_v = 0
            if self.prev_landmarks:
                left_v = self.calculate_velocity(left_wrist, self.prev_landmarks[15], scale_factor, dt)
                right_v = self.calculate_velocity(right_wrist, self.prev_landmarks[16], scale_factor, dt)
            
            self.prev_landmarks = landmarks

            # ==========================
            # ç‹€æ…‹æ©Ÿ
            # ==========================
            
            # 1. ç­‰å¾…è­·è‡‰
            if self.state == 'WAIT_GUARD':
                # åˆ¤æ–·æ¨™æº–ï¼šæ‰‹è…•é«˜æ–¼è‚©è†€ (Yåº§æ¨™æ¯”è¼ƒå°)
                is_guarding = (left_wrist.y < left_shoulder.y) and (right_wrist.y < right_shoulder.y)
                
                if is_guarding:
                    self.state = 'PRE_START'
                    self.wait_until = current_time + random.uniform(1.5, 3.0)
                else:
                    cv2.putText(image, "RAISE HANDS", (int(w/2)-100, int(h/2)), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)

            # 2. éš¨æ©Ÿç­‰å¾…
            elif self.state == 'PRE_START':
                if current_time > self.wait_until:
                    self.state = 'STIMULUS'
                    self.target = random.choice(['LEFT', 'RIGHT'])
                    self.start_time = current_time

            # 3. å‡ºé¡Œ
            elif self.state == 'STIMULUS':
                elapsed = current_time - self.start_time
                
                # é¡¯ç¤ºæŒ‡ä»¤ (0.5ç§’)
                if elapsed < 0.5:
                    text = self.target + "!"
                    color = (0, 0, 255) if self.target == 'LEFT' else (255, 0, 0)
                    font_scale = 3
                    text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, 5)[0]
                    text_x = (w - text_size[0]) // 2
                    text_y = (h + text_size[1]) // 2
                    cv2.putText(image, text, (text_x, text_y), 
                               cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 5)

                # è¶…æ™‚åˆ¤å®š (2ç§’æ²’æ‰“å°±é‡ä¾†)
                if elapsed > 2.0:
                    self.state = 'WAIT_GUARD'

                # å‡ºæ‹³åˆ¤å®š (é–€æª»å·²é™è‡³ 0.12)
                hit = False
                hit_v = 0
                
                if self.target == 'LEFT':
                    # å·¦æ‰‹å¾€å·¦ä¼¸ (x è®Šå°)
                    if (left_wrist.x < left_shoulder.x - self.EXTENSION_THRESHOLD):
                        hit = True
                        hit_v = left_v
                else:
                    # å³æ‰‹å¾€å³ä¼¸ (x è®Šå¤§)
                    if (right_wrist.x > right_shoulder.x + self.EXTENSION_THRESHOLD):
                        hit = True
                        hit_v = right_v
                
                if hit:
                    # å°‡ç§’è½‰æ›ç‚ºæ¯«ç§’ (ms)
                    self.last_reaction_time = elapsed * 1000 
                    self.last_velocity = hit_v
                    self.last_hand = self.target
                    self.state = 'RESULT'
                    self.wait_until = current_time + 3.0

            # 4. é¡¯ç¤ºçµæœ
            elif self.state == 'RESULT':
                # æ•¸æ“šå·²ç”± draw_dashboard è™•ç†
                if current_time > self.wait_until:
                    self.state = 'WAIT_GUARD'

        return image

# ==========================================
# ä¸²æµè™•ç†å™¨
# ==========================================
class VideoProcessor(VideoTransformerBase):
    def __init__(self):
        self.logic = BoxingAnalystLogic()

    def recv(self, frame):
        try:
            img = frame.to_ndarray(format="bgr24")
            img = cv2.flip(img, 1) # é¡åƒ
            img = self.logic.process(img)
            return av.VideoFrame.from_ndarray(img, format="bgr24")
        except Exception as e:
            print(f"Frame Error: {e}")
            return frame

def main():
    st.set_page_config(page_title="æ‹³æ“Šåæ‡‰è¨“ç·´", layout="wide")
    
    st.sidebar.title("ğŸ¥Š æ‹³æ“Šåæ‡‰ v4.0")
    st.sidebar.info(
        """
        **æ•¸æ“šèªªæ˜:**
        - **Time**: åæ‡‰æ™‚é–“ï¼Œå–®ä½æ¯«ç§’ (ms)ã€‚
          - é ‚å°–é¸æ‰‹: 100-200 ms
          - ä¸€èˆ¬äºº: 250-300 ms
        - **Speed**: ç¬é–“å‡ºæ‹³é€Ÿåº¦ (m/s)ã€‚
        
        **åˆ¤å®šæŒ‡ç¤º:**
        - è§€å¯Ÿç•«é¢ä¸‹æ–¹çš„ **Reach Check (ç¶ è‰²æ¢)**ã€‚
        - åªè¦ç¶ è‰²æ¢è¶…éç´…ç·š (é–€æª» 0.12)ï¼Œå³åˆ¤å®šæ“Šä¸­ã€‚
        """
    )
    
    st.title("ğŸ¥Š AI æ‹³æ“Šåæ‡‰æ¸¬è©¦ (msç‰ˆ)")
    st.markdown("è«‹èˆ‰èµ·é›™æ‰‹è­·è‡‰ (Hands Up) é–‹å§‹æ¸¬è©¦ã€‚")

    webrtc_streamer(
        key="boxing-reaction-v4",
        video_processor_factory=VideoProcessor,
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True,
    )

if __name__ == "__main__":
    main()
