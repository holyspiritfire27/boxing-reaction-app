import cv2
import av
import numpy as np
import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase
import time
import random

# ==========================================
# æ ¸å¿ƒä¿®å¾©éƒ¨åˆ†ï¼šMediaPipe å¼•ç”¨æ–¹å¼
# ==========================================
# åœ¨ Streamlit Cloud (Python 3.11/3.13) ä¸Šï¼Œç›´æ¥å‘¼å« mp.solutions.pose æœ‰æ™‚æœƒå¤±æ•ˆ
# å› æ­¤æˆ‘å€‘é€™è£¡ä½¿ç”¨ "from ... import ..." çš„é¡¯å¼å¯«æ³•ä¾†ç¹éé€™å€‹å•é¡Œ
try:
    import mediapipe as mp
    from mediapipe.python.solutions import pose as mp_pose
    from mediapipe.python.solutions import drawing_utils as mp_drawing
except ImportError:
    st.error("ç„¡æ³•åŒ¯å…¥ MediaPipeï¼Œè«‹ç¢ºèª requirements.txt åŒ…å« mediapipe å’Œ protobuf==3.20.3")

# ==========================================
# æ‹³æ“Šåˆ†æé‚è¼¯ (Logic Class)
# ==========================================
class BoxingAnalystLogic:
    def __init__(self):
        # ä½¿ç”¨ä¸Šé¢é¡¯å¼å¼•ç”¨çš„æ¨¡çµ„ï¼Œè€Œä¸æ˜¯ mp.solutions.pose
        self.mp_pose = mp_pose
        self.mp_drawing = mp_drawing
        
        # åˆå§‹åŒ– Pose æ¨¡å‹
        self.pose = self.mp_pose.Pose(
            min_detection_confidence=0.7,
            min_tracking_confidence=0.7,
            model_complexity=1  # 0=Lite, 1=Full, 2=Heavy (å»ºè­° 1 å¹³è¡¡é€Ÿåº¦èˆ‡æº–ç¢ºåº¦)
        )
        
        # éŠæˆ²ç‹€æ…‹è®Šæ•¸
        self.stage = None
        self.counter = 0
        self.last_action_time = 0
        self.reaction_times = []
        self.target = None  # 'LEFT' or 'RIGHT'
        self.waiting_for_action = False
        self.start_time = 0

    def process(self, image):
        # è½‰æ›é¡è‰²ç©ºé–“ BGR -> RGB
        image.flags.writeable = False
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # é€²è¡Œåµæ¸¬
        results = self.pose.process(image_rgb)
        
        # ç•«å›åŸæœ¬çš„åœ–ä¸Š
        image.flags.writeable = True
        image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
        
        # å–å¾—ç•«é¢å°ºå¯¸
        h, w, c = image.shape

        if results.pose_landmarks:
            landmarks = results.pose_landmarks.landmark
            
            # ç¹ªè£½éª¨æ¶
            self.mp_drawing.draw_landmarks(
                image, 
                results.pose_landmarks, 
                self.mp_pose.POSE_CONNECTIONS
            )
            
            # -------------------------------------------------------
            # é€™è£¡æ‚¨å¯ä»¥æ”¾å…¥æ‚¨åŸæœ¬çš„åµæ¸¬é‚è¼¯
            # ä»¥ä¸‹æ˜¯ä¸€å€‹ç°¡å–®çš„ç¯„ä¾‹ï¼šåµæ¸¬å‡ºæ‹³ (æ‰‹è…•è¶…éæ‰‹è‚˜)
            # -------------------------------------------------------
            
            # å–å¾—å·¦æ‰‹åº§æ¨™
            left_wrist = landmarks[self.mp_pose.PoseLandmark.LEFT_WRIST.value]
            left_elbow = landmarks[self.mp_pose.PoseLandmark.LEFT_ELBOW.value]
            
            # å–å¾—å³æ‰‹åº§æ¨™
            right_wrist = landmarks[self.mp_pose.PoseLandmark.RIGHT_WRIST.value]
            right_elbow = landmarks[self.mp_pose.PoseLandmark.RIGHT_ELBOW.value]

            # ç°¡å–®çš„é‚è¼¯ï¼šéš¨æ©Ÿå‡ºé¡Œ
            current_time = time.time()
            
            # å¦‚æœç›®å‰æ²’æœ‰ç›®æ¨™ï¼Œæ¯éš”å¹¾ç§’ç”Ÿæˆä¸€å€‹æ–°ç›®æ¨™
            if not self.target and (current_time - self.last_action_time > 3):
                self.target = random.choice(['LEFT', 'RIGHT'])
                self.start_time = current_time
                self.waiting_for_action = True

            # é¡¯ç¤ºæŒ‡ä»¤
            if self.target:
                color = (0, 0, 255) if self.target == 'LEFT' else (255, 0, 0)
                cv2.putText(image, f"PUNCH {self.target}!", (50, 100), 
                           cv2.FONT_HERSHEY_SIMPLEX, 2, color, 4, cv2.LINE_AA)

            # åµæ¸¬å‹•ä½œæ˜¯å¦å®Œæˆ (ç°¡å–®åˆ¤æ–·ï¼šæ‰‹è…• X è»¸å¤§å¹…ç§»å‹•æˆ– Y è»¸é«˜æ–¼é¼»å­ç­‰ï¼Œé€™è£¡ç¤ºç¯„ X è»¸ä¼¸å±•)
            # æ³¨æ„ï¼šMediaPipe åº§æ¨™æ˜¯æ­¸ä¸€åŒ–çš„ (0~1)
            
            action_detected = None
            
            # ç°¡å–®åˆ¤æ–·ï¼šå¦‚æœæ‰‹è…•éå¸¸æ¥è¿‘ç›¸æ©Ÿ (z è»¸) æˆ– æ‰‹ä¼¸ç›´
            # é€™è£¡ç”¨ä¸€å€‹ç°¡å–®çš„è¦–è¦ºåˆ¤æ–·ï¼šæ‰‹è…•æ¯”æ‰‹è‚˜æ›´é é›¢èº«é«”ä¸­å¿ƒ
            # (é€™åªæ˜¯ä¸€å€‹ç¯„ä¾‹é‚è¼¯ï¼Œè«‹æ›¿æ›å›æ‚¨åŸæœ¬çš„åˆ¤å®šä»£ç¢¼)
            
            # å‡è¨­ï¼šç•¶å·¦æ‰‹è…•çš„ x < å·¦æ‰‹è‚˜ x (ç•«é¢å·¦é‚Š) -> å·¦æ‹³
            if left_wrist.x < left_elbow.x - 0.1:
                action_detected = 'LEFT'
            
            # å‡è¨­ï¼šç•¶å³æ‰‹è…•çš„ x > å³æ‰‹è‚˜ x (ç•«é¢å³é‚Š) -> å³æ‹³
            if right_wrist.x > right_elbow.x + 0.1:
                action_detected = 'RIGHT'

            # æª¢æŸ¥æ˜¯å¦æ“Šä¸­ç›®æ¨™
            if self.waiting_for_action and action_detected == self.target:
                reaction_time = current_time - self.start_time
                self.reaction_times.append(reaction_time)
                self.last_action_time = current_time
                self.target = None # é‡ç½®
                self.waiting_for_action = False
                self.counter += 1

            # é¡¯ç¤ºç‹€æ…‹
            cv2.rectangle(image, (0,0), (250, 73), (245,117,16), -1)
            cv2.putText(image, 'HITS', (15,12), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)
            cv2.putText(image, str(self.counter), (10,60), 
                        cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)

            if self.reaction_times:
                avg_time = np.mean(self.reaction_times)
                cv2.putText(image, f'Avg Time: {avg_time:.2f}s', (260, 60), 
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)

        return image

# ==========================================
# WebRTC å½±åƒè™•ç†å™¨
# ==========================================
class VideoProcessor(VideoTransformerBase):
    def __init__(self):
        self.logic = BoxingAnalystLogic()

    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        
        # äº¤çµ¦é‚è¼¯å±¤è™•ç†
        img = self.logic.process(img)
        
        return av.VideoFrame.from_ndarray(img, format="bgr24")

# ==========================================
# Streamlit ä¸»ç¨‹å¼
# ==========================================
def main():
    st.set_page_config(page_title="Boxing Reaction App", layout="wide")
    
    st.title("ğŸ¥Š Boxing Reaction Trainer")
    st.write("é€™æ˜¯ä¸€å€‹ä½¿ç”¨ MediaPipe çš„æ‹³æ“Šåæ‡‰æ¸¬è©¦ã€‚è«‹å…è¨±ç€è¦½å™¨å­˜å–æ”å½±æ©Ÿã€‚")

    st.sidebar.title("è¨­å®š")
    st.sidebar.info("è«‹ç«™åœ¨è·é›¢é¡é ­ç´„ 1.5 ~ 2 å…¬å°ºè™•ï¼Œç¢ºä¿å…¨èº«å…¥é¡ã€‚")

    # å•Ÿå‹• WebRTC
    webrtc_streamer(
        key="boxing",
        video_processor_factory=VideoProcessor,
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True,
    )

if __name__ == "__main__":
    main()
