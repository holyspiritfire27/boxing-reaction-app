import cv2
import av
import numpy as np
import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase
import time
import random
import mediapipe as mp

# ==========================================
# é‚è¼¯æ ¸å¿ƒé¡åˆ¥
# ==========================================
class BoxingAnalystLogic:
    def __init__(self):
        # MediaPipe è¨­å®š
        self.mp_pose = mp.solutions.pose
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_drawing_styles = mp.solutions.drawing_styles
        
        self.pose = self.mp_pose.Pose(
            min_detection_confidence=0.5, 
            min_tracking_confidence=0.5,
            model_complexity=1
        )
        
        # ç‹€æ…‹ç®¡ç†
        self.state = 'WAIT_GUARD' 
        self.target = None
        self.start_time = 0
        self.wait_until = 0
        
        # æ•¸æ“šè¨˜éŒ„
        self.last_reaction_time = 0.0 # ms
        self.last_velocity = 0.0      # m/s
        self.last_hand = "None"
        
        # â˜… æ–°å¢ï¼šæš«å­˜è©²å›åˆçš„æœ€å¤§é€Ÿåº¦ (è§£æ±ºæŠ“éŒ¯æ™‚é–“é»å•é¡Œ)
        self.max_v_temp = 0.0

        # é€Ÿåº¦è¨ˆç®—è®Šæ•¸
        self.prev_landmarks = None
        self.prev_time = 0
        self.SHOULDER_WIDTH_M = 0.45 

        # åˆ¤å®šåƒæ•¸ (ä½¿ç”¨æ‚¨å»ºè­°çš„ä¼¸å±•é‡åˆ¤å®š)
        self.current_extension = 0.0
        self.EXTENSION_THRESHOLD = 0.12     # ä¼¸å±•é–€æª»
        self.RETRACTION_THRESHOLD = 0.15    # æ­¸ä½é–€æª»
        self.MAX_EXTENSION_DISPLAY = 0.3    

    def calculate_velocity(self, landmark, prev_landmark, scale, dt):
        if dt <= 0: return 0
        dx = landmark.x - prev_landmark.x
        dy = landmark.y - prev_landmark.y
        dz = landmark.z - prev_landmark.z
        dist_px = np.sqrt(dx**2 + dy**2 + dz**2)
        return (dist_px * scale) / dt

    def draw_dashboard(self, image, h, w):
        """ ç¹ªè£½å„€è¡¨æ¿ """
        overlay = image.copy()
        top_y = max(0, h - 160)
        cv2.rectangle(overlay, (10, top_y), (300, h - 10), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.6, image, 0.4, 0, image)
        
        font = cv2.FONT_HERSHEY_SIMPLEX
        white = (255, 255, 255)
        
        # --- ç‹€æ…‹é¡¯ç¤º ---
        if self.state == 'WAIT_GUARD': 
            status_text = "RESET: HANDS BACK" 
            status_color = (0, 165, 255) # æ©˜è‰²
        elif self.state == 'PRE_START': 
            status_text = "READY..."
            status_color = (0, 255, 255) # é»ƒè‰²
        elif self.state == 'STIMULUS': 
            status_text = "GO !!!"
            status_color = (0, 0, 255) # ç´…è‰²
        else:
            status_text = "RESULT"
            status_color = (0, 255, 0)
            
        cv2.putText(image, f"{status_text}", (20, h - 120), font, 0.8, status_color, 2)

        # --- æ•¸æ“šé¡¯ç¤º ---
        if self.last_reaction_time > 0:
            r_time_str = f"{int(self.last_reaction_time)} ms" 
        else:
            r_time_str = "---"
            
        vel_str = f"{self.last_velocity:.1f} m/s" if self.last_velocity > 0 else "---"
        
        cv2.putText(image, f"Time: {r_time_str}", (20, h - 80), font, 0.9, white, 2)
        cv2.putText(image, f"Peak Speed: {vel_str}", (20, h - 40), font, 0.7, white, 2)

        # --- Extension Check Bar ---
        bar_x = 320
        bar_w = 200
        bar_h = 20
        bar_y = h - 40
        cv2.rectangle(image, (bar_x, bar_y), (bar_x + bar_w, bar_y + bar_h), (255,255,255), 2)
        
        # ç´…è‰²é–¾å€¼ç·š
        threshold_ratio = self.EXTENSION_THRESHOLD / self.MAX_EXTENSION_DISPLAY
        threshold_x = int(bar_x + threshold_ratio * bar_w)
        cv2.line(image, (threshold_x, bar_y - 5), (threshold_x, bar_y + bar_h + 5), (0,0,255), 2)
        
        # å¡«å……
        fill_ratio = self.current_extension / self.MAX_EXTENSION_DISPLAY
        fill_len = int(fill_ratio * bar_w)
        fill_len = max(0, min(fill_len, bar_w))
        color = (0, 255, 0) if self.current_extension > self.EXTENSION_THRESHOLD else (0, 255, 255)
        cv2.rectangle(image, (bar_x, bar_y), (bar_x + fill_len, bar_y + bar_h), color, -1)
        cv2.putText(image, "Reach", (bar_x, bar_y - 10), font, 0.5, white, 1)

    def process(self, image):
        image.flags.writeable = False
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = self.pose.process(image_rgb)
        
        image.flags.writeable = True
        image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
        h, w, c = image.shape
        
        current_time = time.time()
        dt = current_time - self.prev_time
        self.prev_time = current_time

        self.draw_dashboard(image, h, w)

        if results.pose_landmarks:
            landmarks = results.pose_landmarks.landmark
            self.mp_drawing.draw_landmarks(
                image, results.pose_landmarks, self.mp_pose.POSE_CONNECTIONS,
                landmark_drawing_spec=self.mp_drawing_styles.get_default_pose_landmarks_style()
            )

            # é—œéµé»
            left_shoulder = landmarks[11]
            right_shoulder = landmarks[12]
            left_wrist = landmarks[15]
            right_wrist = landmarks[16]
            
            # â˜… 1. è¨ˆç®—ä¼¸å±•é‡ (é€™å°±æ˜¯ Extension Bar ç”¨çš„æ•¸å€¼)
            # é€™è£¡æˆ‘å€‘åªå– X è»¸è·é›¢çµ•å°å€¼ï¼Œé€™å°æ­£æ‹³æˆ–å´æ‹³éƒ½æ¯”è¼ƒå¯¬å®¹
            dist_l = abs(left_wrist.x - left_shoulder.x)
            dist_r = abs(right_wrist.x - right_shoulder.x)
            self.current_extension = max(dist_l, dist_r)

            # è¨ˆç®—æ¯”ä¾‹
            shoulder_dist = np.sqrt((left_shoulder.x - right_shoulder.x)**2 + 
                                    (left_shoulder.y - right_shoulder.y)**2)
            scale_factor = self.SHOULDER_WIDTH_M / shoulder_dist if shoulder_dist > 0 else 0

            # è¨ˆç®—ç•¶å‰é€Ÿåº¦
            left_v = 0
            right_v = 0
            if self.prev_landmarks:
                left_v = self.calculate_velocity(left_wrist, self.prev_landmarks[15], scale_factor, dt)
                right_v = self.calculate_velocity(right_wrist, self.prev_landmarks[16], scale_factor, dt)
            
            self.prev_landmarks = landmarks

            # ==========================
            # ç‹€æ…‹æ©Ÿ
            # ==========================
            if self.state == 'WAIT_GUARD':
                # æ­¸ä½åˆ¤å®š (æ‰‹è¦æ”¶å›ä¾†)
                is_hands_up = (left_wrist.y < left_shoulder.y + 0.2) and \
                              (right_wrist.y < right_shoulder.y + 0.2)
                
                # ç¢ºä¿æ‰‹æ˜¯ç¸®è‘—çš„
                is_retracted = (dist_l < self.RETRACTION_THRESHOLD) and \
                               (dist_r < self.RETRACTION_THRESHOLD)
                
                if is_hands_up and is_retracted:
                    self.state = 'PRE_START'
                    self.wait_until = current_time + random.uniform(1.5, 3.0)
                    self.max_v_temp = 0.0 # é‡ç½®é€Ÿåº¦ç´€éŒ„
                else:
                    if int(current_time * 2) % 2 == 0:
                        cv2.putText(image, "NEXT ROUND", (int(w/2)-150, int(h/2)-20), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 255), 3)
                    cv2.putText(image, "HANDS UP & BACK", (int(w/2)-200, int(h/2)+50), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)

            elif self.state == 'PRE_START':
                if current_time > self.wait_until:
                    self.state = 'STIMULUS'
                    self.target = random.choice(['LEFT', 'RIGHT'])
                    self.start_time = current_time
                    self.max_v_temp = 0.0 # å†æ¬¡ç¢ºä¿é‡ç½®

            elif self.state == 'STIMULUS':
                elapsed = current_time - self.start_time
                
                # â˜… 2. æ›´æ–°æœ€å¤§é€Ÿåº¦ (Peak Velocity Tracking)
                # åªè¦é‚„åœ¨å‡ºæ‹³éšæ®µï¼Œå°±ä¸æ–·ç´€éŒ„æœ€å¿«çš„é‚£ä¸€ç¬é–“
                current_max_v = max(left_v, right_v)
                if current_max_v > self.max_v_temp:
                    self.max_v_temp = current_max_v

                # é¡¯ç¤ºæŒ‡ä»¤
                if elapsed < 0.8:
                    text = self.target + "!"
                    color = (0, 0, 255) if self.target == 'LEFT' else (255, 0, 0)
                    font_scale = 4
                    text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, 8)[0]
                    text_x = (w - text_size[0]) // 2
                    text_y = (h + text_size[1]) // 2
                    cv2.putText(image, text, (text_x, text_y), 
                               cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 8)

                if elapsed > 3.0:
                    self.state = 'WAIT_GUARD'

                # â˜… 3. æ“Šä¸­åˆ¤å®š (æ”¹ç”¨ä¼¸å±•é‡åˆ¤å®š)
                # é€™è·Ÿ Extension Bar çš„é‚è¼¯å®Œå…¨ä¸€è‡´ï¼ŒBar è¶…éç´…ç·š = Hit
                hit = False
                
                if self.target == 'LEFT':
                    if dist_l > self.EXTENSION_THRESHOLD:
                        hit = True
                else:
                    if dist_r > self.EXTENSION_THRESHOLD:
                        hit = True
                
                if hit:
                    self.last_reaction_time = elapsed * 1000 # ms
                    # ä½¿ç”¨ç´€éŒ„åˆ°çš„æœ€å¤§é€Ÿåº¦ï¼Œè€Œä¸æ˜¯ç•¶ä¸‹çš„æ®˜å½±
                    self.last_velocity = self.max_v_temp 
                    self.last_hand = self.target
                    
                    self.state = 'RESULT'
                    self.wait_until = current_time + 2.0 

            elif self.state == 'RESULT':
                if current_time > self.wait_until:
                    self.state = 'WAIT_GUARD'

        return image

class VideoProcessor(VideoTransformerBase):
    def __init__(self):
        self.logic = BoxingAnalystLogic()

    def recv(self, frame):
        try:
            img = frame.to_ndarray(format="bgr24")
            img = cv2.flip(img, 1)
            img = self.logic.process(img)
            return av.VideoFrame.from_ndarray(img, format="bgr24")
        except Exception as e:
            print(f"Error: {e}")
            return frame

def main():
    st.set_page_config(page_title="æ‹³æ“Šåæ‡‰è¨“ç·´ v7", layout="wide")
    st.sidebar.title("ğŸ¥Š æ‹³æ“Šåæ‡‰ v7.0")
    st.sidebar.info(
        """
        **æ ¸å¿ƒæ›´æ–°:**
        1. **åˆ¤å®šä¿®å¾©**: ç¾åœ¨åªè¦ Extension Bar (ç¶ æ¢) è¶…éç´…ç·šï¼Œå°±ä¿è­‰æœƒè§¸ç™¼åˆ¤å®šã€‚
        2. **å³°å€¼é€Ÿåº¦**: ç³»çµ±æœƒæ•æ‰å‡ºæ‹³éç¨‹ä¸­æœ€å¿«çš„ä¸€ç¬é–“ï¼Œæ•¸æ“šä¸å†é¡¯ç¤ºéä½çš„æ•¸å€¼ã€‚
        
        **ç©æ³•:**
        - çœ‹åˆ° **GO** æŒ‡ä»¤å‡ºæ‹³ã€‚
        - ç¶ æ¢è¶…éç´…ç·šå³ç®—å¾—åˆ†ã€‚
        - æ‰“å®Œå‹™å¿…**æ”¶æ‹³**ï¼Œç­‰å¾…ä¸‹ä¸€å±€ã€‚
        """
    )
    st.title("ğŸ¥Š AI æ‹³æ“Šåæ‡‰æ¸¬è©¦ (é‚è¼¯ä¿®å¾©ç‰ˆ)")
    webrtc_streamer(
        key="boxing-reaction-v7",
        video_processor_factory=VideoProcessor,
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True,
    )

if __name__ == "__main__":
    main()
